import streamlit as st
import os
import time
import json
import tempfile
import zipfile
import io
import re
import subprocess
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
from pydub import AudioSegment

# Google Cloud & Gemini
from google.cloud import speech
import google.generativeai as genai
from google.oauth2 import service_account

# ==================== åŒ¯å…¥è¨­å®šæª” ====================
GCP_CREDENTIALS = None
GEMINI_API_KEY = None
CONFIG_LOADED = False

if "gcp_service_account" in st.secrets and "GEMINI_API_KEY" in st.secrets:
    try:
        GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
        creds_dict = dict(st.secrets["gcp_service_account"])
        if "private_key" in creds_dict:
            creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
        GCP_CREDENTIALS = creds_dict
        CONFIG_LOADED = True
    except Exception as e:
        st.error(f"è®€å– Secrets æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

if not CONFIG_LOADED:
    try:
        from config import GCP_CREDENTIALS as Local_GCP, GEMINI_API_KEY as Local_Gemini
        GCP_CREDENTIALS = Local_GCP
        GEMINI_API_KEY = Local_Gemini
        CONFIG_LOADED = True
    except ImportError:
        pass

if not CONFIG_LOADED:
    st.error("âŒ æ‰¾ä¸åˆ°è¨­å®šæª”ï¼")
    st.stop()

# ==================== è¨­å®šèˆ‡ UI åˆå§‹åŒ– ====================
st.set_page_config(page_title="æ·é‹ç·Šæ€¥èªéŸ³è½‰è­¯å°", page_icon="ğŸ™ï¸", layout="wide")
st.title("ğŸ™ï¸ æ·é‹ç·Šæ€¥èªéŸ³è½‰è­¯å·¥å…· (Webç‰ˆ)")

# æ·é‹å°ˆæ¥­è¡“èª
RAILWAY_PHRASES = [
    "OCC", "è¡Œæ§ä¸­å¿ƒ", "å‘¼å«", "è»Œé“", "æœˆå°", 
    "Bypass", "VVVF", "ç•°ç‰©", "è»Šé–€", "è™Ÿè»Š",
    "ç·Šæ€¥", "åœè»Š", "æ·¨ç©º", "æ–¹å½¢é‘°åŒ™", "G9", "G7"
]

with st.sidebar:
    st.header("âš™ï¸ ç³»çµ±è¨­å®š")
    if GCP_CREDENTIALS: st.success("âœ… Google STT è¨­å®šå®Œæˆ")
    if GEMINI_API_KEY: st.success("âœ… Gemini API è¨­å®šå®Œæˆ")
    st.markdown("---")
    mode = st.radio("é¸æ“‡è½‰è­¯æ¨¡å¼", ["åƒ… Google STT", "åƒ… Gemini", "é›™æ¨¡å¼ (æ¯”è¼ƒ)"])
    st.markdown("---")
    chunk_duration = st.slider("éŸ³è¨Šåˆ‡åˆ†é•·åº¦ (ç§’)", 30, 58, 50, 5, help="ç‚ºé¿å…APIé™åˆ¶ï¼Œå»ºè­°è¨­ç‚º50ç§’")

# ==================== å·¥å…·å‡½æ•¸ ====================
def format_duration(seconds):
    return str(timedelta(seconds=int(seconds)))

def extract_datetime_from_filename(filename):
    try:
        name = Path(filename).stem
        parts = name.split('_')
        if len(parts) >= 2:
            return datetime.strptime(f"{parts[0]}{parts[1]}", "%Y%m%d%H%M%S")
    except:
        pass
    return datetime.now()

# ==================== [æ ¸å¿ƒä¿®æ­£] è½‰è­¯é‚è¼¯ ====================

def transcribe_google_stt(audio_path, filename, max_chunk_duration=50):
    """
    ä¿®æ­£é»ï¼š
    1. åˆ‡åˆ†æ™‚è¼¸å‡º raw (s16le) æ ¼å¼ï¼Œè€Œé wavï¼Œä»¥åŒ¹é… LINEAR16 è¨­å®šã€‚
    2. æ¨¡å‹æ”¹ç”¨ 'default'ï¼Œæ¯” 'latest_long' åœ¨çŸ­èªéŸ³å’Œç„¡ç·šé›»ä¸­æ›´ç©©å®šã€‚
    """
    try:
        credentials = service_account.Credentials.from_service_account_info(GCP_CREDENTIALS)
        client = speech.SpeechClient(credentials=credentials)
        
        audio_segment = AudioSegment.from_file(audio_path)
        duration_seconds = len(audio_segment) / 1000.0
        
        # è¨­å®šè¾¨è­˜åƒæ•¸
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16, # é æœŸ Raw PCM
            sample_rate_hertz=16000,
            language_code="cmn-Hant-TW",
            enable_automatic_punctuation=True,
            model="default", # ä¿®æ­£ï¼šæ”¹ç”¨æ¨™æº–æ¨¡å‹
            use_enhanced=True, # ä¿®æ­£ï¼šå•Ÿç”¨å¢å¼·æ¨¡å¼
            speech_contexts=[speech.SpeechContext(phrases=RAILWAY_PHRASES, boost=20)]
        )
        
        # æº–å‚™åˆ‡åˆ†
        chunk_duration_ms = int(max_chunk_duration * 1000)
        transcripts = []
        
        # è™•ç†å–®æ®µæˆ–å¤šæ®µ
        for i in range(0, len(audio_segment), chunk_duration_ms):
            chunk = audio_segment[i:i + chunk_duration_ms]
            
            # [é—œéµä¿®æ­£] è½‰ç‚º Raw PCM (s16le)ï¼Œä¸å¸¶ WAV æª”é ­
            chunk_io = io.BytesIO()
            chunk.export(chunk_io, format="s16le", parameters=["-ac", "1", "-ar", "16000"])
            chunk_bytes = chunk_io.getvalue()
            
            try:
                audio = speech.RecognitionAudio(content=chunk_bytes)
                response = client.recognize(config=config, audio=audio)
                
                chunk_text = "".join([result.alternatives[0].transcript for result in response.results])
                transcripts.append(chunk_text)
            except Exception as e:
                print(f"Chunk error: {e}")
                transcripts.append("") # å®¹éŒ¯ï¼Œå¿½ç•¥è©²æ®µéŒ¯èª¤

        full_transcript = "".join(transcripts)
        return full_transcript if full_transcript.strip() else "[ç„¡æ³•è¾¨è­˜å…§å®¹]"
        
    except Exception as e:
        return f"[STT éŒ¯èª¤: {str(e)[:100]}]"

def transcribe_gemini(audio_path):
    """
    ä¿®æ­£é»ï¼š
    1. ç›´æ¥æ¥æ”¶ WAV æª”æ¡ˆï¼Œä¸ä½¿ç”¨ M4Aã€‚
    2. æ˜ç¢ºæŒ‡å®š mime_type ç‚º audio/wavã€‚
    """
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        with open(audio_path, 'rb') as f:
            audio_bytes = f.read()
            
        # æç¤ºè©å„ªåŒ–
        prompt = """
        ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ·é‹ç„¡ç·šé›»é€šè¨Šç´€éŒ„å“¡ã€‚è«‹å°‡éŸ³æª”è½‰éŒ„ç‚ºé€å­—ç¨¿ã€‚
        
        é‡è¦è¦å‰‡ï¼š
        1. å…§å®¹åŒ…å«å°ç£æ·é‹è¡“èª (å¦‚: OCC, G9, G7, è»Œé“, æ–·è·¯å™¨)ã€‚
        2. é€™æ˜¯ç„¡ç·šé›»é€šè©±ï¼Œå¯èƒ½æœƒæœ‰é›œè¨Šï¼Œè«‹æ ¹æ“šä¸Šä¸‹æ–‡ä¿®æ­£èªå¥ã€‚
        3. è¼¸å‡ºæ ¼å¼ï¼šç´”æ–‡å­—ï¼Œä¸è¦ä»»ä½• markdown æ¨™é¡Œæˆ–é¡å¤–èªªæ˜ã€‚
        4. è‹¥æœ‰è¬›è€…ä»£è™Ÿ (å¦‚: å¸æ©Ÿå“¡, è¡Œæ§) è«‹æ¨™ç¤ºã€‚
        """
        
        response = model.generate_content([
            prompt,
            {
                "mime_type": "audio/wav", # ä¿®æ­£ï¼šç›´æ¥ä½¿ç”¨ wav
                "data": audio_bytes
            }
        ])
        
        return response.text.strip() if response.text else "[ç„¡æ³•è¾¨è­˜å…§å®¹]"
            
    except Exception as e:
        if "400" in str(e):
            return "[Gemini éŒ¯èª¤: æ ¼å¼ä¸æ”¯æ´æˆ–æª”æ¡ˆææ¯€]"
        return f"[Gemini éŒ¯èª¤: {str(e)[:100]}]"

# ==================== å ±å‘Šç”Ÿæˆé‚è¼¯ (ä¿æŒä¸è®Š) ====================
def generate_merged_content(records):
    lines = []
    lines.append("â•" * 60)
    lines.append(f"ç”Ÿæˆæ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    lines.append("â•" * 60 + "\n")
    for record in records:
        lines.append(f"[{record['filename']}]")
        lines.append(record['transcript'])
        lines.append("-" * 30 + "\n")
    return "\n".join(lines)

def generate_comparison_report(stt_records, gemini_records):
    lines = ["STT vs Gemini æ¯”è¼ƒå ±å‘Š", "="*40]
    for stt, gem in zip(stt_records, gemini_records):
        lines.append(f"æª”æ¡ˆ: {stt['filename']}")
        lines.append(f"Google STT: {stt['transcript']}")
        lines.append(f"Gemini    : {gem['transcript']}")
        lines.append("-" * 40)
    return "\n".join(lines)

# ==================== ä¸»ç¨‹å¼é‚è¼¯ ====================

uploaded_files = st.file_uploader("é¸æ“‡éŒ„éŸ³æª”", type=['wav', 'mp3', 'm4a', 'flac'], accept_multiple_files=True)

if st.button("ğŸš€ é–‹å§‹è½‰è­¯", type="primary") and uploaded_files:
    stt_records = []
    gemini_records = []
    progress_bar = st.progress(0)
    status_text = st.empty()

    with tempfile.TemporaryDirectory() as temp_dir:
        for i, uploaded_file in enumerate(uploaded_files):
            # 1. å„²å­˜åŸå§‹æª”
            temp_path = os.path.join(temp_dir, uploaded_file.name)
            with open(temp_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            # 2. çµ±ä¸€è½‰æª”ç‚º 16k WAV (é›™æ¨¡å¼å…±ç”¨æ­¤æª”æ¡ˆ)
            # é€™æ˜¯æœ€ç©©å®šçš„æ ¼å¼ï¼šGoogle STT (è®€ raw data) å’Œ Gemini (è®€ wav file) éƒ½èƒ½ç”¨
            wav_path = os.path.join(temp_dir, f"converted_{i}.wav")
            
            status_text.text(f"ğŸ”„ è½‰æª”ä¸­ï¼š{uploaded_file.name}...")
            try:
                subprocess.run([
                    'ffmpeg', '-i', temp_path,
                    '-ar', '16000', '-ac', '1', '-acodec', 'pcm_s16le',
                    '-y', wav_path
                ], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            except subprocess.CalledProcessError:
                st.error(f"è½‰æª”å¤±æ•—: {uploaded_file.name}")
                continue

            # å–å¾—éŸ³è¨Šé•·åº¦
            try:
                sound = AudioSegment.from_file(wav_path)
                duration_sec = len(sound) / 1000.0
            except:
                duration_sec = 0

            base_dt = extract_datetime_from_filename(uploaded_file.name)

            # 3. åŸ·è¡Œè¾¨è­˜
            use_stt = "Google STT" in mode or "é›™æ¨¡å¼" in mode
            use_gemini = "Gemini" in mode or "é›™æ¨¡å¼" in mode

            if use_stt:
                status_text.text(f"ğŸ¤ STT è¾¨è­˜ä¸­...")
                # å‚³å…¥ wav_pathï¼Œä½†åœ¨å‡½æ•¸å…§éƒ¨æœƒè½‰ç‚º raw bytes
                res = transcribe_google_stt(wav_path, uploaded_file.name, chunk_duration)
                stt_records.append({'filename': uploaded_file.name, 'datetime': base_dt, 'duration_sec': duration_sec, 'transcript': res})

            if use_gemini:
                status_text.text(f"ğŸ¤– Gemini è¾¨è­˜ä¸­...")
                # ç›´æ¥å‚³å…¥ wav_path
                res = transcribe_gemini(wav_path)
                gemini_records.append({'filename': uploaded_file.name, 'datetime': base_dt, 'duration_sec': duration_sec, 'transcript': res})

            progress_bar.progress((i + 1) / len(uploaded_files))

    status_text.success("âœ¨ è™•ç†å®Œæˆï¼")

    # ==================== é¡¯ç¤ºçµæœ ====================
    tabs = []
    if use_stt: tabs.append("Google STT")
    if use_gemini: tabs.append("Gemini")
    if use_stt and use_gemini: tabs.append("æ¯”è¼ƒ")
    
    tab_objs = st.tabs(tabs)
    
    zip_buffer = io.BytesIO()
    with zipfile.ZipFile(zip_buffer, "w") as zf:
        if use_stt:
            with tab_objs[0]:
                txt = generate_merged_content(stt_records)
                st.text_area("STT çµæœ", txt, height=300)
                zf.writestr("GoogleSTT_Result.txt", txt)
        
        if use_gemini:
            idx = 1 if use_stt else 0
            with tab_objs[idx]:
                txt = generate_merged_content(gemini_records)
                st.text_area("Gemini çµæœ", txt, height=300)
                zf.writestr("Gemini_Result.txt", txt)

        if use_stt and use_gemini:
            with tab_objs[2]:
                comp_txt = generate_comparison_report(stt_records, gemini_records)
                st.text_area("æ¯”è¼ƒå ±å‘Š", comp_txt, height=300)
                zf.writestr("Comparison_Report.txt", comp_txt)

    st.download_button("ğŸ“¥ ä¸‹è¼‰çµæœ (ZIP)", zip_buffer.getvalue(), "transcripts.zip", "application/zip")
